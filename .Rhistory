# Detach all loaded packages and clean your environment
golem::detach_all_attached()
# rm(list=ls(all.names = TRUE))
# Document and reload your package
golem::document_and_reload()
# Run the application
run_app()
# Set options here
options(golem.app.prod = FALSE) # TRUE = production mode, FALSE = development mode
# Comment this if you don't want the app to be served on a random port
options(shiny.port = httpuv::randomPort())
# Detach all loaded packages and clean your environment
golem::detach_all_attached()
# rm(list=ls(all.names = TRUE))
# Document and reload your package
golem::document_and_reload()
# Run the application
run_app()
# Set options here
options(golem.app.prod = FALSE) # TRUE = production mode, FALSE = development mode
# Comment this if you don't want the app to be served on a random port
options(shiny.port = httpuv::randomPort())
# Detach all loaded packages and clean your environment
golem::detach_all_attached()
# rm(list=ls(all.names = TRUE))
# Document and reload your package
golem::document_and_reload()
# Run the application
run_app()
# Set options here
options(golem.app.prod = FALSE) # TRUE = production mode, FALSE = development mode
# Comment this if you don't want the app to be served on a random port
options(shiny.port = httpuv::randomPort())
# Detach all loaded packages and clean your environment
golem::detach_all_attached()
# rm(list=ls(all.names = TRUE))
# Document and reload your package
golem::document_and_reload()
# Run the application
run_app()
# Set options here
options(golem.app.prod = FALSE) # TRUE = production mode, FALSE = development mode
# Comment this if you don't want the app to be served on a random port
options(shiny.port = httpuv::randomPort())
# Detach all loaded packages and clean your environment
golem::detach_all_attached()
# rm(list=ls(all.names = TRUE))
# Document and reload your package
golem::document_and_reload()
# Run the application
run_app()
# Set options here
options(golem.app.prod = FALSE) # TRUE = production mode, FALSE = development mode
# Comment this if you don't want the app to be served on a random port
options(shiny.port = httpuv::randomPort())
# Detach all loaded packages and clean your environment
golem::detach_all_attached()
# rm(list=ls(all.names = TRUE))
# Document and reload your package
golem::document_and_reload()
# Run the application
run_app()
# Set options here
options(golem.app.prod = FALSE) # TRUE = production mode, FALSE = development mode
# Comment this if you don't want the app to be served on a random port
options(shiny.port = httpuv::randomPort())
# Detach all loaded packages and clean your environment
golem::detach_all_attached()
# rm(list=ls(all.names = TRUE))
# Document and reload your package
golem::document_and_reload()
# Run the application
run_app()
# Set options here
options(golem.app.prod = FALSE) # TRUE = production mode, FALSE = development mode
# Comment this if you don't want the app to be served on a random port
options(shiny.port = httpuv::randomPort())
# Detach all loaded packages and clean your environment
golem::detach_all_attached()
# rm(list=ls(all.names = TRUE))
# Document and reload your package
golem::document_and_reload()
# Run the application
run_app()
# Set options here
options(golem.app.prod = FALSE) # TRUE = production mode, FALSE = development mode
# Comment this if you don't want the app to be served on a random port
options(shiny.port = httpuv::randomPort())
# Detach all loaded packages and clean your environment
golem::detach_all_attached()
# rm(list=ls(all.names = TRUE))
# Document and reload your package
golem::document_and_reload()
# Run the application
run_app()
# Set options here
options(golem.app.prod = FALSE) # TRUE = production mode, FALSE = development mode
# Comment this if you don't want the app to be served on a random port
options(shiny.port = httpuv::randomPort())
# Detach all loaded packages and clean your environment
golem::detach_all_attached()
# rm(list=ls(all.names = TRUE))
# Document and reload your package
golem::document_and_reload()
# Run the application
run_app()
# Set options here
options(golem.app.prod = FALSE) # TRUE = production mode, FALSE = development mode
# Comment this if you don't want the app to be served on a random port
options(shiny.port = httpuv::randomPort())
# Detach all loaded packages and clean your environment
golem::detach_all_attached()
# rm(list=ls(all.names = TRUE))
# Document and reload your package
golem::document_and_reload()
# Run the application
run_app()
# Set options here
options(golem.app.prod = FALSE) # TRUE = production mode, FALSE = development mode
# Comment this if you don't want the app to be served on a random port
options(shiny.port = httpuv::randomPort())
# Detach all loaded packages and clean your environment
golem::detach_all_attached()
# rm(list=ls(all.names = TRUE))
# Document and reload your package
golem::document_and_reload()
# Run the application
run_app()
# Set options here
options(golem.app.prod = FALSE) # TRUE = production mode, FALSE = development mode
# Comment this if you don't want the app to be served on a random port
options(shiny.port = httpuv::randomPort())
# Detach all loaded packages and clean your environment
golem::detach_all_attached()
# rm(list=ls(all.names = TRUE))
# Document and reload your package
golem::document_and_reload()
# Run the application
run_app()
# Set options here
options(golem.app.prod = FALSE) # TRUE = production mode, FALSE = development mode
# Comment this if you don't want the app to be served on a random port
options(shiny.port = httpuv::randomPort())
# Detach all loaded packages and clean your environment
golem::detach_all_attached()
# rm(list=ls(all.names = TRUE))
# Document and reload your package
golem::document_and_reload()
# Run the application
run_app()
# Set options here
options(golem.app.prod = FALSE) # TRUE = production mode, FALSE = development mode
# Comment this if you don't want the app to be served on a random port
options(shiny.port = httpuv::randomPort())
# Detach all loaded packages and clean your environment
golem::detach_all_attached()
# rm(list=ls(all.names = TRUE))
# Document and reload your package
golem::document_and_reload()
# Run the application
run_app()
# Set options here
options(golem.app.prod = FALSE) # TRUE = production mode, FALSE = development mode
# Comment this if you don't want the app to be served on a random port
options(shiny.port = httpuv::randomPort())
# Detach all loaded packages and clean your environment
golem::detach_all_attached()
# rm(list=ls(all.names = TRUE))
# Document and reload your package
golem::document_and_reload()
# Run the application
run_app()
shiny::runApp()
runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
shiny::runApp()
runApp()
shiny::runApp()
shiny::runApp()
test_file("tests/testthat/test-fct_partial_cors.R")
shiny::runApp()
?loadSupport
runApp()
test_file("tests/testthat/test-fct_partial_cors.R")
test_file("tests/testthat/test-fct_partial_cors.R")
View(precargados_metab_exp)
test_file("tests/testthat/test-fct_partial_cors.R")
test_file("tests/testthat/test-fct_partial_cors.R")
test_file("tests/testthat/test-fct_partial_cors.R")
test_file("tests/testthat/test-fct_partial_cors.R")
runApp()
test_file("tests/testthat/test-fct_partial_cors.R")
test_file("tests/testthat/test-fct_partial_cors.R")
example_data <- data.frame(
Feature_ID = paste0("Gene", 1:10),
Sample1 = rnorm(10),
Sample2 = rnorm(10),
Sample3 = rnorm(10),
Sample4 = rnorm(10)
)
View(example_data)
# Add some rows with NA values to test filtering
example_data[1, 2] <- NA
example_data[2, 3] <- NA
result <- partial_cors(example_data)
View(result)
# Check that the result is a matrix
expect_true(is.matrix(result))
result <- partial_cors(example_data)
Expression_mat = example_data
Expression_mat$missing_count <- rowSums(is.na(Expression_mat))
View(Expression_mat)
feature_mat_ <- subset(Expression_mat, missing_count <= 0.1 * (ncol(Expression_mat) - 2))
View(feature_mat_)
feature_mat <- subset(Expression_mat, missing_count <= 0.1 * (ncol(Expression_mat) - 2))
features <- feature_mat$Feature_ID
feature_mat_t <- t(feature_mat[, -c(1, ncol(feature_mat))])
View(feature_mat_t)
View(example_data)
colnames(feature_mat_t) <- features
feature_mat_t <- feature_mat_t[, apply(feature_mat_t, 2, function(x) length(unique(x)) > 1)]
# Ensure all columns are numeric
feature_mat_t <- as.data.frame(feature_mat_t)
feature_mat_t[] <- lapply(feature_mat_t, as.numeric)
feature_mat_t <- as.matrix(feature_mat_t)
Expression_mat = example_data
Expression_mat$missing_count <- rowSums(is.na(Expression_mat))
feature_mat <- subset(Expression_mat, missing_count <= 0.1 * (ncol(Expression_mat) - 2))
features <- feature_mat$Feature_ID
feature_mat_t <- t(feature_mat[, -c(1, ncol(feature_mat))])
View(Expression_mat)
Expression_mat = example_data
#Expression_mat = Expression_mat
Expression_mat$missing_count <- rowSums(is.na(Expression_mat))
feature_mat <- subset(Expression_mat, missing_count <= 0.1 * (ncol(Expression_mat) - 2))
features <- feature_mat$Feature_ID
feature_mat_t <- t(feature_mat[, -c(1, ncol(feature_mat))])
colnames(feature_mat_t) <- features
feature_mat_t <- feature_mat_t[, apply(feature_mat_t, 2, function(x) length(unique(x)) > 1)]
# Ensure all columns are numeric
feature_mat_t <- as.data.frame(feature_mat_t)
feature_mat_t[] <- lapply(feature_mat_t, as.numeric)
feature_mat_t <- as.matrix(feature_mat_t)
feature_mat_t <- as.matrix(scale(feature_mat_t))
sd_values <- apply(feature_mat_t, 2, function(x) sd(x, na.rm = TRUE))
filtered_indices <- which(sd_values > quantile(sd_values, 0.25))
View(feature_mat_t)
feature_mat_t <- if (length(filtered_indices) > 20000) {
feature_mat_t[, order(sd_values[filtered_indices], decreasing = TRUE)[1:20000]]
} else {
feature_mat_t[, filtered_indices]
}
# generate covariance matrix
cov_mat = cov(as.matrix(feature_mat_t), use = "pairwise.complete.obs")
# calculate partial correlations
glassoFast_result = glassoFast::glassoFast(cov_mat, .25, thr = 1e-04,
maxIt = 10000, start = "cold",
trace = FALSE)
# extract just partial correlation result
partial_cor_mat = glassoFast_result$wi
# set diagonal values to 0; hierarchical clustering will give an error with NA diagonal values
diag(partial_cor_mat) = NA
# set row/colnames to match feature matrix
rownames(partial_cor_mat) = colnames(feature_mat_t)
colnames(partial_cor_mat) = colnames(feature_mat_t)
# return the resulting partial correlations
return(partial_cor_mat)
View(partial_cor_mat)
View(result)
# Calculate the expected number of rows after filtering
filtered_data <- example_data[rowSums(is.na(example_data)) <= 0.1 * (ncol(example_data) - 2), ]
View(filtered_data)
# Create an example dataset
set.seed(123)
example_data <- data.frame(
Feature_ID = paste0("Gene", 1:10),
Sample1 = rnorm(10),
Sample2 = rnorm(10),
Sample3 = rnorm(10),
Sample4 = rnorm(10)
)
# Add some rows with NA values to test filtering
example_data[1, 2] <- NA
example_data[2, 3] <- NA
test_that("partial_cors returns a matrix with correct dimensions and NA diagonal", {
result <- partial_cors(example_data)
# Check that the result is a matrix
expect_true(is.matrix(result))
# Calculate the expected number of rows after filtering
filtered_data <- example_data[rowSums(is.na(example_data[, -1])) <= 0.1 * (ncol(example_data) - 2), ]
feature_mat_t <- t(filtered_data[, -c(1, ncol(filtered_data))])
feature_mat_t <- feature_mat_t[, apply(feature_mat_t, 2, function(x) length(unique(x)) > 1)]
feature_mat_t <- as.matrix(scale(feature_mat_t))
sd_values <- apply(feature_mat_t, 2, function(x) sd(x, na.rm = TRUE))
filtered_indices <- which(sd_values > quantile(sd_values, 0.25))
expected_rows <- length(filtered_indices)
expect_equal(nrow(result), expected_rows)
expect_equal(ncol(result), expected_rows)
# Check that the diagonal contains NA
expect_true(all(is.na(diag(result))))
})
result <- partial_cors(example_data)
# Create an example dataset
set.seed(123)
example_data <- data.frame(
Feature_ID = paste0("Gene", 1:10),
Sample1 = rnorm(10),
Sample2 = rnorm(10),
Sample3 = rnorm(10),
Sample4 = rnorm(10)
)
# Add some rows with NA values to test filtering
example_data[1, 2] <- NA
example_data[2, 3] <- NA
result <- partial_cors(example_data)
View(partial_cor_mat)
result <- partial_cors(example_data)
example_data <- data.frame(
Feature_ID = paste0("Gene", 1:10),
Sample1 = rnorm(10),
Sample2 = rnorm(10),
Sample3 = rnorm(10),
Sample4 = rnorm(10)
)
# Add some rows with NA values to test filtering
example_data[1, 2] <- NA
example_data[2, 3] <- NA
# Create an example dataset
set.seed(123)
example_data <- data.frame(
Feature_ID = paste0("Gene", 1:10),
Sample1 = rnorm(10),
Sample2 = rnorm(10),
Sample3 = rnorm(10),
Sample4 = rnorm(10)
)
# Add some rows with NA values to test filtering
example_data[1, 2] <- NA
example_data[2, 3] <- NA
test_that("partial_cors returns a matrix with correct dimensions and NA diagonal", {
result <- partial_cors(example_data)
# Check that the result is a matrix
expect_true(is.matrix(result))
# Calculate the expected number of rows after filtering
filtered_data <- example_data[rowSums(is.na(example_data[, -1])) <= 0.1 * (ncol(example_data) - 2), ]
feature_mat_t <- t(filtered_data[, -c(1, ncol(filtered_data))])
feature_mat_t <- feature_mat_t[, apply(feature_mat_t, 2, function(x) length(unique(x)) > 1)]
feature_mat_t <- as.matrix(scale(feature_mat_t))
sd_values <- apply(feature_mat_t, 2, function(x) sd(x, na.rm = TRUE))
filtered_indices <- which(sd_values > quantile(sd_values, 0.25))
expected_rows <- length(filtered_indices)
expect_equal(nrow(result), expected_rows)
expect_equal(ncol(result), expected_rows)
# Check that the diagonal contains NA
expect_true(all(is.na(diag(result))))
})
result <- partial_cors(example_data)
# Create an example dataset
set.seed(123)
example_data <- data.frame(
Feature_ID = paste0("Gene", 1:10),
Sample1 = rnorm(10),
Sample2 = rnorm(10),
Sample3 = rnorm(10),
Sample4 = rnorm(10)
)
# Add some rows with NA values to test filtering
example_data[1, 2] <- NA
example_data[2, 3] <- NA
result <- partial_cors(example_data)
Expression_mat = example_data
Expression_mat$missing_count <- rowSums(is.na(Expression_mat))
feature_mat <- subset(Expression_mat, missing_count <= 0.1 * (ncol(Expression_mat) - 2))
features <- feature_mat$Feature_ID
feature_mat_t <- t(feature_mat[, -c(1, ncol(feature_mat))])
colnames(feature_mat_t) <- features
feature_mat_t <- feature_mat_t[, apply(feature_mat_t, 2, function(x) length(unique(x)) > 1)]
# Ensure all columns are numeric
feature_mat_t <- as.data.frame(feature_mat_t)
feature_mat_t[] <- lapply(feature_mat_t, as.numeric)
feature_mat_t <- as.matrix(feature_mat_t)
feature_mat_t <- as.matrix(scale(feature_mat_t))
sd_values <- apply(feature_mat_t, 2, function(x) sd(x, na.rm = TRUE))
filtered_indices <- which(sd_values > quantile(sd_values, 0.25))
feature_mat_t <- if (length(filtered_indices) > 20000) {
feature_mat_t[, order(sd_values[filtered_indices], decreasing = TRUE)[1:20000]]
} else {
feature_mat_t[, filtered_indices]
}
# generate covariance matrix
cov_mat = cov(as.matrix(feature_mat_t), use = "pairwise.complete.obs")
# calculate partial correlations
glassoFast_result = glassoFast::glassoFast(cov_mat, .25, thr = 1e-04,
maxIt = 10000, start = "cold",
trace = FALSE)
# extract just partial correlation result
partial_cor_mat = glassoFast_result$wi
# set diagonal values to 0; hierarchical clustering will give an error with NA diagonal values
diag(partial_cor_mat) = NA
# set row/colnames to match feature matrix
rownames(partial_cor_mat) = colnames(feature_mat_t)
# Check that the result is a matrix
expect_true(is.matrix(result))
# Calculate the expected number of rows after filtering
filtered_data <- example_data[rowSums(is.na(example_data[, -1])) <= 0.1 * (ncol(example_data) - 2), ]
View(example_data)
feature_mat_t <- t(filtered_data[, -c(1, ncol(filtered_data))])
# Calculate the expected number of rows after filtering
filtered_data <- example_data[rowSums(is.na(example_data[, -1])) <= 0.1 * (ncol(example_data) - 2), ]
feature_mat_t <- t(filtered_data[, -1])
feature_mat_t <- feature_mat_t[, apply(feature_mat_t, 2, function(x) length(unique(x)) > 1)]
feature_mat_t <- as.matrix(scale(feature_mat_t))
sd_values <- apply(feature_mat_t, 2, function(x) sd(x, na.rm = TRUE))
filtered_indices <- which(sd_values > quantile(sd_values, 0.25))
expected_rows <- length(filtered_indices)
expect_equal(nrow(result), expected_rows)
expect_equal(ncol(result), expected_rows)
# Check that the diagonal contains NA
expect_true(all(is.na(diag(result))))
test_that("partial_cors returns a matrix with correct dimensions and NA diagonal", {
result <- partial_cors(example_data)
# Check that the result is a matrix
expect_true(is.matrix(result))
# Calculate the expected number of rows after filtering
filtered_data <- example_data[rowSums(is.na(example_data[, -1])) <= 0.1 * (ncol(example_data) - 2), ]
feature_mat_t <- t(filtered_data[, -1])
feature_mat_t <- feature_mat_t[, apply(feature_mat_t, 2, function(x) length(unique(x)) > 1)]
feature_mat_t <- as.matrix(scale(feature_mat_t))
sd_values <- apply(feature_mat_t, 2, function(x) sd(x, na.rm = TRUE))
filtered_indices <- which(sd_values > quantile(sd_values, 0.25))
expected_rows <- length(filtered_indices)
expect_equal(nrow(result), expected_rows)
expect_equal(ncol(result), expected_rows)
# Check that the diagonal contains NA
expect_true(all(is.na(diag(result))))
})
test_that("partial_cors handles missing values correctly", {
result <- partial_cors(example_data)
# Check that rows with too many NAs have been removed
expect_true(!"Gene1" %in% rownames(result))
expect_true(!"Gene2" %in% rownames(result))
})
test_that("partial_cors scales the data correctly", {
result <- partial_cors(example_data)
# Check that the data has been scaled (mean 0 and standard deviation 1)
scaled_data <- scale(t(example_data[, -c(1, ncol(example_data))]))
expect_equal(colMeans(scaled_data, na.rm = TRUE), rep(0, ncol(scaled_data)), tolerance = 1e-8)
expect_equal(apply(scaled_data, 2, sd, na.rm = TRUE), rep(1, ncol(scaled_data)), tolerance = 1e-8)
})
test_file("tests/testthat/test-fct_partial_cors.R")
devtools::test()
devtools::check()
runApp()
Imports:
roxygen2 (>= 7.3.2)
runApp()
devtools::check()
runApp()
devtools::document()
devtools::check()
devtools::check()
devtools::document()
devtools::check()
devtools::document()
devtools::check()
devtools::document()
devtools::check()
file.rename("LICENSE.R", "LICENSE")
devtools::document()
devtools::check()
devtools::document()
devtools::check()
tools::showNonASCIIfile("R/mod_module1.R")
devtools::document()
devtools::check()
devtools::document()
shiny::runApp('inst/shiny')
runApp('inst/shiny')
runApp('inst/shiny')
runApp('inst/shiny')
system.file("Example_data", "ccRCC4_Data", "Metab_exp.csv", package = "iModMix")
runApp('inst/shiny')
runApp()
devtools::document()
runApp()
runApp()
devtools::document()
devtools::check()
runApp()
runApp()
runApp()
runApp()
devtools::document()
devtools::check()
runApp()
runApp()
devtools::document()
devtools::check()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
